# üìã An√°lisis Profesional del Proyecto Vibrant + Plan de Implementaci√≥n AI

**Fecha:** 6 de Febrero, 2026  
**Autor:** An√°lisis de Arquitectura de Software  
**Proyecto:** Vibrant CLI Linter

---

## üéØ Resumen Ejecutivo

**Tu idea es EXCELENTE y muy viable.** Vibrant tiene una arquitectura s√≥lida y bien pensada que facilita la adici√≥n de features AI. La estrategia de tener una versi√≥n gratuita con reglas b√°sicas + una versi√≥n `--ai` premium es un modelo de negocio probado (similar a GitHub Copilot, Cursor, etc.).

**Potencial del proyecto:**
- ‚úÖ Problema real: Detectar c√≥digo generado por IA que puede tener issues sutiles
- ‚úÖ Arquitectura limpia y extensible
- ‚úÖ Tecnolog√≠a moderna (Bun, TypeScript)
- ‚úÖ Buen UX con m√∫ltiples formatos de salida
- ‚úÖ Modelo de monetizaci√≥n claro

---

## üìä Estado Actual del Proyecto

### Estructura General
```
vibrant/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ cli/              # El linter principal (tu producto core)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linter/   # Motor de an√°lisis
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rules/      # Reglas individuales (3 actualmente)
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parser.ts   # Parser de c√≥digo TypeScript
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ runner.ts   # Ejecutor de reglas
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types.ts    # Tipos del sistema
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.ts   # Configuraci√≥n (no usado a√∫n)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bin.ts     # Entry point del CLI
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cli.ts     # Definici√≥n de comandos
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ glob.ts    # B√∫squeda de archivos
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ runner.ts  # Orquestador principal
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ web/              # Landing page (placeholder)
‚îî‚îÄ‚îÄ package.json          # Workspace config
```

### C√≥mo Funciona Actualmente

**Flujo de ejecuci√≥n:**
```
Usuario ejecuta: vibrant .
    ‚Üì
CLI parsea argumentos (cli.ts)
    ‚Üì
Runner busca archivos TS/JS (glob.ts)
    ‚Üì
Para cada archivo:
    ‚Üì
    Parser crea AST con TypeScript Compiler API
    ‚Üì
    Se ejecutan las 3 reglas:
        1. generic-comment      ‚Üí Detecta // TODO: implement
        2. generic-variable-name ‚Üí Detecta variables como "data", "temp"
        3. no-explicit-any      ‚Üí Detecta uso de "any"
    ‚Üì
    Colecta diagn√≥sticos (errores/warnings/info)
    ‚Üì
Formatea salida (pretty/json/compact)
    ‚Üì
Imprime resultados en terminal
```

### Reglas Actuales (Versi√≥n Free)

#### 1. `generic-comment`
**Archivo:** `apps/cli/src/linter/rules/generic-comment.ts`

**Qu√© detecta:**
```typescript
// ‚ùå Detecta estos patrones:
// TODO: implement
// FIX: this
// Fix this
/* TODO: implement this later */
```

**Por qu√© es importante:**
Los LLMs (GPT, Claude) suelen dejar comentarios gen√©ricos cuando no saben exactamente qu√© implementar.

**Output ejemplo:**
```
‚ö† warning 15:3 Comentario gen√©rico tipo "vibecode": "// TODO: implement..."
    üí° Reemplaza por un comentario concreto que describa qu√© hacer o por qu√©.
```

---

#### 2. `generic-variable-name`
**Archivo:** `apps/cli/src/linter/rules/generic-variable-name.ts`

**Qu√© detecta:**
```typescript
// ‚ùå Nombres muy gen√©ricos:
const data = await fetch(...);
const result = calculate();
const temp = x;
const value = y;
const item = list[0];
const obj = {};
const arr = [];
const response = await api();
```

**Por qu√© es importante:**
Los LLMs tienden a usar nombres super gen√©ricos porque no conocen el contexto de dominio de tu app.

**Output ejemplo:**
```
‚Ñπ info 23:7 Nombre de variable muy gen√©rico "data"
    üí° Considera un nombre m√°s descriptivo para este √°mbito.
```

---

#### 3. `no-explicit-any`
**Archivo:** `apps/cli/src/linter/rules/no-explicit-any.ts`

**Qu√© detecta:**
```typescript
// ‚ùå Uso expl√≠cito de any:
function process(data: any) { ... }
const result: any = await fetch();
```

**Por qu√© es importante:**
Los LLMs usan `any` cuando no est√°n seguros del tipo, perdiendo type safety.

**Output ejemplo:**
```
‚ö† warning 42:15 Uso expl√≠cito de `any`
    üí° Usa un tipo m√°s espec√≠fico o `unknown` si el tipo es realmente desconocido.
```

---

## üí° Tu Idea: Versi√≥n AI con --ai Flag

### Concepto
```bash
# Versi√≥n FREE (reglas b√°sicas)
$ vibrant .

# Versi√≥n AI (an√°lisis profundo con LLM)
$ vibrant . --ai
```

### Por Qu√© Es Brillante

1. **Democratizaci√≥n:** La versi√≥n free ayuda a todos
2. **Upsell Natural:** Los usuarios ven valor y quieren m√°s
3. **Costo Variable:** Solo pagas API cuando el usuario lo usa
4. **Diferenciaci√≥n:** No solo patterns est√°ticos, sino an√°lisis sem√°ntico real

### Modelo de Negocio Sugerido

**Opci√≥n 1: BYOK (Bring Your Own Key)**
```bash
# Usuario provee su API key
$ export OPENAI_API_KEY=sk-...
$ vibrant . --ai
```
- Pro: Sin costo para ti
- Pro: Sin billing complejo
- Con: Fricci√≥n para el usuario

**Opci√≥n 2: Cr√©ditos Propios**
```bash
# Usuario se registra y compra cr√©ditos
$ vibrant login
$ vibrant . --ai  # Consume tus cr√©ditos
```
- Pro: Mejor UX
- Pro: Puedes agregar markup
- Con: Requiere backend + billing

**Recomendaci√≥n:** Empieza con BYOK (m√°s simple), luego agrega cr√©ditos propios.

---

## üîß Plan de Implementaci√≥n T√©cnica

### Fase 1: Arquitectura Base AI (1-2 semanas)

#### Paso 1.1: Crear Servicio AI
**Crear:** `apps/cli/src/ai/service.ts`

```typescript
// Abstracci√≥n para m√∫ltiples providers
export interface AIProvider {
  name: 'openai' | 'anthropic';
  analyze(code: string, context: AnalysisContext): Promise<AIAnalysis>;
}

export interface AnalysisContext {
  filePath: string;
  fileContent: string;
  existingDiagnostics: Diagnostic[];
  projectContext?: string;
}

export interface AIAnalysis {
  confidence: number; // 0-1 que tan seguro est√° que es AI-generated
  issues: AIIssue[];
  suggestions: string[];
}

export interface AIIssue {
  type: 'semantic' | 'pattern' | 'best-practice' | 'security';
  severity: 'error' | 'warning' | 'info';
  line: number;
  column: number;
  message: string;
  explanation: string; // Por qu√© es un problema
  suggestedFix?: string; // C√≥digo corregido
  confidence: number; // Confianza en este issue espec√≠fico
}

export class AIService {
  private provider: AIProvider;

  constructor(apiKey: string, providerType: 'openai' | 'anthropic') {
    this.provider = this.createProvider(apiKey, providerType);
  }

  private createProvider(apiKey: string, type: 'openai' | 'anthropic'): AIProvider {
    if (type === 'openai') {
      return new OpenAIProvider(apiKey);
    } else {
      return new AnthropicProvider(apiKey);
    }
  }

  async analyzeFile(context: AnalysisContext): Promise<AIAnalysis> {
    return await this.provider.analyze(context.fileContent, context);
  }
}
```

**Por qu√© esta estructura:**
- **Abstracci√≥n:** Soporta OpenAI y Claude con la misma interfaz
- **Extensible:** F√°cil agregar m√°s providers (Gemini, Llama, etc.)
- **Type-safe:** Todo con TypeScript

---

#### Paso 1.2: Implementar Provider OpenAI
**Crear:** `apps/cli/src/ai/providers/openai.ts`

```typescript
import OpenAI from 'openai';
import type { AIProvider, AnalysisContext, AIAnalysis } from '../service.js';

export class OpenAIProvider implements AIProvider {
  name = 'openai' as const;
  private client: OpenAI;

  constructor(apiKey: string) {
    this.client = new OpenAI({ apiKey });
  }

  async analyze(code: string, context: AnalysisContext): Promise<AIAnalysis> {
    const prompt = this.buildPrompt(code, context);
    
    const response = await this.client.chat.completions.create({
      model: 'gpt-4-turbo-preview', // O gpt-4o
      messages: [
        {
          role: 'system',
          content: SYSTEM_PROMPT
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      response_format: { type: 'json_object' }, // Structured output
      temperature: 0.3 // M√°s determinista
    });

    const result = JSON.parse(response.choices[0].message.content!);
    return this.parseResponse(result);
  }

  private buildPrompt(code: string, context: AnalysisContext): string {
    return `
Analiza este c√≥digo TypeScript/JavaScript y detecta si fue generado por IA.

Archivo: ${context.filePath}

C√≥digo:
\`\`\`typescript
${code}
\`\`\`

Issues ya detectados por reglas est√°ticas:
${JSON.stringify(context.existingDiagnostics, null, 2)}

Tareas:
1. Determina la probabilidad (0-1) de que este c√≥digo fue generado por IA
2. Encuentra problemas SEM√ÅNTICOS que las reglas est√°ticas no detectan:
   - L√≥gica correcta sint√°cticamente pero incorrecta sem√°nticamente
   - Nombres de variables t√©cnicamente v√°lidos pero sin sentido de dominio
   - Patrones que "huelen" a c√≥digo generado (ej: exceso de abstracciones)
   - Comentarios que no aportan valor
   - C√≥digo innecesariamente complejo
3. Sugerencias concretas de mejora CON ejemplos de c√≥digo

Responde en JSON con esta estructura:
{
  "confidence": 0.85,
  "issues": [
    {
      "type": "semantic",
      "severity": "warning",
      "line": 10,
      "column": 5,
      "message": "Nombre de variable no refleja el dominio del negocio",
      "explanation": "...",
      "suggestedFix": "const userProfile = ...",
      "confidence": 0.9
    }
  ],
  "suggestions": [
    "Considera usar nombres m√°s espec√≠ficos del dominio",
    "Simplifica la l√≥gica de validaci√≥n"
  ]
}
`;
  }

  private parseResponse(result: any): AIAnalysis {
    // Validaci√≥n y parsing del response
    return {
      confidence: result.confidence,
      issues: result.issues,
      suggestions: result.suggestions
    };
  }
}

const SYSTEM_PROMPT = `
Eres un experto en detecci√≥n de c√≥digo generado por IA y an√°lisis de calidad de c√≥digo.
Tu trabajo es identificar patrones sutiles que indican que el c√≥digo fue generado por un LLM.

Caracter√≠sticas comunes de c√≥digo AI-generated:
- Nombres gen√©ricos (data, result, temp, value)
- Comentarios obvios que no agregan informaci√≥n
- Exceso de try-catch sin manejo espec√≠fico
- L√≥gica correcta pero sin contexto de dominio
- Abstracciones innecesarias
- C√≥digo excesivamente "perfecto" o estilizado
- Falta de edge cases espec√≠ficos del dominio

Tu an√°lisis debe ser:
- Preciso: Solo reporta problemas reales
- Contextual: Entiende el prop√≥sito del c√≥digo
- Accionable: Da sugerencias concretas con ejemplos
- Educativo: Explica POR QU√â es un problema
`;
```

**Por qu√© este approach:**
- **Structured Output:** JSON parsing confiable con `response_format`
- **Baja temperatura:** An√°lisis m√°s consistente (menos creativo)
- **Contexto rico:** Le pasamos las reglas est√°ticas para evitar duplicados
- **System prompt claro:** Define exactamente qu√© buscar

---

#### Paso 1.3: Implementar Provider Anthropic (Claude)
**Crear:** `apps/cli/src/ai/providers/anthropic.ts`

```typescript
import Anthropic from '@anthropic-ai/sdk';
import type { AIProvider, AnalysisContext, AIAnalysis } from '../service.js';

export class AnthropicProvider implements AIProvider {
  name = 'anthropic' as const;
  private client: Anthropic;

  constructor(apiKey: string) {
    this.client = new Anthropic({ apiKey });
  }

  async analyze(code: string, context: AnalysisContext): Promise<AIAnalysis> {
    const prompt = this.buildPrompt(code, context);
    
    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20241022', // √öltimo modelo
      max_tokens: 4096,
      temperature: 0.3,
      system: SYSTEM_PROMPT,
      messages: [
        {
          role: 'user',
          content: prompt
        }
      ]
    });

    // Claude puede devolver m√∫ltiples content blocks
    const textContent = response.content.find(c => c.type === 'text');
    if (!textContent || textContent.type !== 'text') {
      throw new Error('No text response from Claude');
    }

    // Extraer JSON del response (Claude a veces lo envuelve en markdown)
    const jsonMatch = textContent.text.match(/```json\n([\s\S]*?)\n```/) || 
                      textContent.text.match(/\{[\s\S]*\}/);
    
    if (!jsonMatch) {
      throw new Error('Could not parse JSON from Claude response');
    }

    const result = JSON.parse(jsonMatch[1] || jsonMatch[0]);
    return this.parseResponse(result);
  }

  private buildPrompt(code: string, context: AnalysisContext): string {
    // Similar al de OpenAI, pero optimizado para Claude
    return `
<task>
Analiza este c√≥digo para determinar si fue generado por IA y encuentra problemas sem√°nticos.
</task>

<file>
Path: ${context.filePath}

\`\`\`typescript
${code}
\`\`\`
</file>

<existing_issues>
${JSON.stringify(context.existingDiagnostics, null, 2)}
</existing_issues>

<instructions>
1. Calcula la probabilidad (0-1) de que este c√≥digo fue generado por IA
2. Identifica problemas SEM√ÅNTICOS que las reglas est√°ticas no pueden detectar
3. Proporciona sugerencias concretas con ejemplos de c√≥digo

Enf√≥cate en:
- L√≥gica correcta sint√°cticamente pero incorrecta para el dominio
- Nombres v√°lidos pero sin sentido contextual
- Patrones t√≠picos de LLMs (abstracciones excesivas, comentarios obvios)
- Manejo de errores gen√©rico
- Falta de casos edge espec√≠ficos del problema
</instructions>

<output_format>
Responde SOLO con un objeto JSON v√°lido (sin markdown):
{
  "confidence": 0.85,
  "issues": [
    {
      "type": "semantic",
      "severity": "warning",
      "line": 10,
      "column": 5,
      "message": "...",
      "explanation": "...",
      "suggestedFix": "...",
      "confidence": 0.9
    }
  ],
  "suggestions": [
    "...",
    "..."
  ]
}
</output_format>
`;
  }

  private parseResponse(result: any): AIAnalysis {
    return {
      confidence: result.confidence,
      issues: result.issues,
      suggestions: result.suggestions
    };
  }
}

const SYSTEM_PROMPT = `
Eres un experto senior en an√°lisis de c√≥digo y detecci√≥n de patrones de c√≥digo generado por IA.

Tu tarea es realizar un an√°lisis profundo y contextual del c√≥digo, identificando:
1. Probabilidad de que fue generado por un LLM
2. Problemas sem√°nticos que no son detectables por an√°lisis est√°tico
3. Mejoras concretas y accionables

Caracter√≠sticas de c√≥digo AI-generated:
- Nombres t√©cnicamente correctos pero sin contexto de dominio
- Comentarios que explican lo obvio
- L√≥gica gen√©rica que funciona pero no es espec√≠fica del problema
- Exceso de abstracci√≥n sin necesidad real
- Try-catch blocks gen√©ricos sin manejo espec√≠fico
- Falta de validaciones espec√≠ficas del dominio
- C√≥digo "demasiado perfecto" sin consideraciones pr√°cticas

S√© preciso, contextual y educativo en tus recomendaciones.
`;
```

**Diferencias con OpenAI:**
- Claude usa XML-style prompts (m√°s efectivo para Claude)
- Parsing m√°s robusto (Claude a veces envuelve JSON en markdown)
- Modelo m√°s reciente (sonnet-3.5)

---

#### Paso 1.4: Actualizar CLI para Soportar --ai
**Modificar:** `apps/cli/src/cli.ts`

```typescript
import { Command } from "commander";
import { lintCommand } from "./commands/lint.js";
import { rulesCommand } from "./commands/rules.js";
import { initCommand } from "./commands/init.js";

const program = new Command();

program
  .name("vibrant")
  .description("Linter para detectar c√≥digo vibecodeado (AI-generated)")
  .version("0.2.0");

// Comando principal de linting
program
  .command("lint")
  .description("Analiza archivos en busca de c√≥digo vibecodeado")
  .argument("[path]", "Ruta a analizar", ".")
  .option("-f, --format <type>", "Formato de salida: pretty, json, compact", "pretty")
  .option("--ignore <patterns>", "Patrones a ignorar (separados por coma)", "")
  .option("--ai", "ü§ñ Habilita an√°lisis profundo con IA", false) // NUEVA OPCI√ìN
  .option("--ai-provider <provider>", "Provider de IA: openai, anthropic", "openai")
  .action(lintCommand);

// Comando para listar reglas
program
  .command("rules")
  .description("Lista todas las reglas disponibles")
  .option("--ai", "Incluye informaci√≥n sobre an√°lisis AI")
  .action(rulesCommand);

// Comando para inicializar configuraci√≥n
program
  .command("init")
  .description("Crea un archivo de configuraci√≥n vibrant.config.js")
  .action(initCommand);

export default program;
```

---

#### Paso 1.5: Modificar el Runner para Soportar AI
**Modificar:** `apps/cli/src/commands/lint.ts` (crear si no existe)

```typescript
import { AIService } from "../ai/service.js";
import { lint } from "../runner.js";
import pc from "picocolors";

interface LintOptions {
  format: "pretty" | "json" | "compact";
  ignore: string;
  ai: boolean;
  aiProvider: "openai" | "anthropic";
}

export async function lintCommand(path: string, options: LintOptions) {
  let aiService: AIService | undefined;

  // Si --ai est√° activado, configurar el servicio
  if (options.ai) {
    const apiKey = getAPIKey(options.aiProvider);
    
    if (!apiKey) {
      console.error(pc.red("\n‚ùå Error: API Key no encontrada"));
      console.error(pc.yellow("\nPara usar --ai, configura tu API key:"));
      
      if (options.aiProvider === "openai") {
        console.error(pc.cyan("  export OPENAI_API_KEY=sk-..."));
      } else {
        console.error(pc.cyan("  export ANTHROPIC_API_KEY=sk-ant-..."));
      }
      
      console.error(pc.dim("\nO crea un archivo .env con:"));
      console.error(pc.cyan(`  ${options.aiProvider.toUpperCase()}_API_KEY=...`));
      process.exit(1);
    }

    console.log(pc.green(`\nü§ñ An√°lisis AI habilitado (${options.aiProvider})`));
    console.log(pc.dim("Esto consumir√° cr√©ditos de tu API key\n"));

    aiService = new AIService(apiKey, options.aiProvider);
  }

  // Ejecutar el linting
  const result = await lint(path, {
    format: options.format,
    ignore: options.ignore ? options.ignore.split(",") : [],
    aiService, // Pasar el servicio AI si est√° disponible
  });

  // Manejar exit code
  if (result.issues.length > 0) {
    process.exit(1);
  }
}

function getAPIKey(provider: "openai" | "anthropic"): string | undefined {
  const envVar = provider === "openai" ? "OPENAI_API_KEY" : "ANTHROPIC_API_KEY";
  
  // Primero intentar desde env
  let apiKey = process.env[envVar];
  
  // Si no est√°, intentar desde .env file
  if (!apiKey) {
    try {
      // Bun tiene soporte nativo para .env
      apiKey = Bun.env[envVar];
    } catch {
      // Silently fail
    }
  }
  
  return apiKey;
}
```

---

#### Paso 1.6: Integrar AI en el Runner Principal
**Modificar:** `apps/cli/src/runner.ts`

```typescript
import { lintFile } from "./linter/runner.js";
import { globFiles } from "./glob.js";
import type { LinterOptions, LinterResult } from "./types.js";
import type { AIService } from "./ai/service.js";
import pc from "picocolors";

interface ExtendedLinterOptions extends LinterOptions {
  aiService?: AIService;
}

export async function lint(
  path: string,
  options: ExtendedLinterOptions
): Promise<LinterResult> {
  const startTime = Date.now();
  
  // Buscar archivos
  const files = await globFiles(path, options.ignore || []);
  
  if (files.length === 0) {
    console.log(pc.yellow("No se encontraron archivos para analizar"));
    return {
      issues: [],
      filesAnalyzed: 0,
      filesWithIssues: 0,
      duration: Date.now() - startTime,
    };
  }

  console.log(pc.dim(`Analizando ${files.length} archivos...\n`));

  // Analizar cada archivo
  const allIssues = [];
  let filesWithIssues = 0;

  for (const file of files) {
    // 1. Ejecutar reglas est√°ticas (siempre)
    const staticDiagnostics = await lintFile(file);
    
    // 2. Si hay AI service, ejecutar an√°lisis AI
    let aiDiagnostics = [];
    if (options.aiService) {
      try {
        const fileContent = await Bun.file(file).text();
        
        const aiAnalysis = await options.aiService.analyzeFile({
          filePath: file,
          fileContent,
          existingDiagnostics: staticDiagnostics,
        });

        // Convertir AIIssue a Diagnostic
        aiDiagnostics = aiAnalysis.issues.map(issue => ({
          file,
          line: issue.line,
          column: issue.column,
          message: issue.message,
          severity: issue.severity,
          ruleId: `ai:${issue.type}`,
          suggestion: issue.suggestedFix,
          explanation: issue.explanation,
          confidence: issue.confidence,
        }));

        // Agregar el confidence score general como metadata
        if (aiAnalysis.confidence > 0.7) {
          aiDiagnostics.unshift({
            file,
            line: 1,
            column: 1,
            message: `Este archivo tiene ${Math.round(aiAnalysis.confidence * 100)}% de probabilidad de ser c√≥digo AI-generated`,
            severity: "info",
            ruleId: "ai:confidence",
            confidence: aiAnalysis.confidence,
          });
        }

      } catch (error) {
        console.error(pc.red(`Error al analizar ${file} con AI:`), error);
      }
    }

    // Combinar diagn√≥sticos
    const allDiagnostics = [...staticDiagnostics, ...aiDiagnostics];
    
    if (allDiagnostics.length > 0) {
      filesWithIssues++;
      allIssues.push(...allDiagnostics);
    }

    // Progress indicator
    if (options.format === "pretty") {
      process.stdout.write(pc.dim("."));
    }
  }

  if (options.format === "pretty") {
    process.stdout.write("\n\n");
  }

  // Formatear y mostrar resultados
  formatOutput(allIssues, options.format);

  const duration = Date.now() - startTime;
  printSummary(files.length, filesWithIssues, allIssues.length, duration);

  return {
    issues: allIssues,
    filesAnalyzed: files.length,
    filesWithIssues,
    duration,
  };
}

function formatOutput(issues: any[], format: string) {
  if (format === "json") {
    console.log(JSON.stringify(issues, null, 2));
  } else if (format === "compact") {
    for (const issue of issues) {
      console.log(
        `${issue.file}:${issue.line}:${issue.column} ${issue.severity} ${issue.message}`
      );
    }
  } else {
    // Pretty format
    const byFile = groupByFile(issues);
    
    for (const [file, fileIssues] of Object.entries(byFile)) {
      console.log(pc.bold(pc.cyan(file)));
      
      for (const issue of fileIssues as any[]) {
        const icon = getSeverityIcon(issue.severity);
        const color = getSeverityColor(issue.severity);
        
        console.log(
          `  ${color(icon)} ${issue.severity} ${pc.dim(`${issue.line}:${issue.column}`)} ${issue.message}`
        );
        
        if (issue.confidence) {
          console.log(
            pc.dim(`      Confianza: ${Math.round(issue.confidence * 100)}%`)
          );
        }
        
        if (issue.explanation) {
          console.log(pc.dim(`      ${issue.explanation}`));
        }
        
        if (issue.suggestion) {
          console.log(pc.green(`      üí° ${issue.suggestion}`));
        }
      }
      
      console.log(); // Blank line
    }
  }
}

function groupByFile(issues: any[]): Record<string, any[]> {
  return issues.reduce((acc, issue) => {
    if (!acc[issue.file]) {
      acc[issue.file] = [];
    }
    acc[issue.file].push(issue);
    return acc;
  }, {});
}

function getSeverityIcon(severity: string): string {
  switch (severity) {
    case "error": return "‚ùå";
    case "warning": return "‚ö†Ô∏è";
    case "info": return "‚ÑπÔ∏è";
    default: return "‚Ä¢";
  }
}

function getSeverityColor(severity: string) {
  switch (severity) {
    case "error": return pc.red;
    case "warning": return pc.yellow;
    case "info": return pc.blue;
    default: return pc.white;
  }
}

function printSummary(total: number, withIssues: number, issueCount: number, duration: number) {
  console.log(pc.bold("\nüìä Resumen:"));
  console.log(`  Archivos analizados: ${total}`);
  console.log(`  Archivos con issues: ${withIssues}`);
  console.log(`  Total de issues: ${issueCount}`);
  console.log(pc.dim(`  Tiempo: ${duration}ms`));
}
```

---

#### Paso 1.7: Actualizar Tipos
**Modificar:** `apps/cli/src/types.ts`

```typescript
import type { AIService } from "./ai/service.js";

export interface LintIssue {
  ruleId: string;
  message: string;
  severity: "error" | "warning" | "info";
  line: number;
  column: number;
  file: string;
  suggestion?: string;
  explanation?: string; // NUEVO: para explicaciones AI
  confidence?: number;  // NUEVO: confianza del AI (0-1)
}

export interface LinterOptions {
  path: string;
  format?: "pretty" | "json" | "compact";
  ignore?: string[];
  aiService?: AIService; // NUEVO
}

export interface LinterResult {
  issues: LintIssue[];
  filesAnalyzed: number;
  filesWithIssues: number;
  duration: number;
}
```

---

### Fase 2: Testing y Refinamiento (1 semana)

#### Paso 2.1: Tests Unitarios
**Crear:** `apps/cli/src/ai/__tests__/service.test.ts`

```typescript
import { test, expect, mock } from "bun:test";
import { AIService } from "../service.js";
import type { AnalysisContext } from "../service.js";

test("AIService - OpenAI provider", async () => {
  const mockAnalyze = mock(() => Promise.resolve({
    confidence: 0.85,
    issues: [],
    suggestions: ["Use m√°s espec√≠ficos nombres"]
  }));

  const service = new AIService("test-key", "openai");
  // @ts-ignore - override for testing
  service.provider.analyze = mockAnalyze;

  const context: AnalysisContext = {
    filePath: "test.ts",
    fileContent: "const data = 123;",
    existingDiagnostics: []
  };

  const result = await service.analyzeFile(context);
  
  expect(result.confidence).toBe(0.85);
  expect(mockAnalyze).toHaveBeenCalledTimes(1);
});

test("AIService - handles API errors gracefully", async () => {
  const service = new AIService("invalid-key", "openai");
  
  const context: AnalysisContext = {
    filePath: "test.ts",
    fileContent: "const x = 1;",
    existingDiagnostics: []
  };

  await expect(service.analyzeFile(context)).rejects.toThrow();
});
```

#### Paso 2.2: Integration Tests
**Crear:** `apps/cli/src/__tests__/integration.test.ts`

```typescript
import { test, expect } from "bun:test";
import { $ } from "bun";

test("CLI - basic linting works", async () => {
  const result = await $`bun run cli . --format json`.text();
  const parsed = JSON.parse(result);
  
  expect(Array.isArray(parsed)).toBe(true);
});

test("CLI - --ai requires API key", async () => {
  // Remover la key temporalmente
  const originalKey = process.env.OPENAI_API_KEY;
  delete process.env.OPENAI_API_KEY;
  
  const proc = Bun.spawn(["bun", "run", "cli", ".", "--ai"]);
  const exitCode = await proc.exited;
  
  expect(exitCode).toBe(1);
  
  // Restaurar
  if (originalKey) {
    process.env.OPENAI_API_KEY = originalKey;
  }
});
```

---

### Fase 3: Features Avanzadas (2-3 semanas)

#### Feature 3.1: Caching de An√°lisis AI
**Crear:** `apps/cli/src/ai/cache.ts`

```typescript
import { createHash } from "crypto";

export class AICache {
  private cache: Map<string, any> = new Map();
  private maxSize = 100; // M√°ximo 100 archivos en cach√©

  getCacheKey(fileContent: string): string {
    return createHash("sha256").update(fileContent).digest("hex");
  }

  get(fileContent: string): any | undefined {
    const key = this.getCacheKey(fileContent);
    return this.cache.get(key);
  }

  set(fileContent: string, analysis: any): void {
    const key = this.getCacheKey(fileContent);
    
    // Si el cach√© est√° lleno, borrar el m√°s viejo
    if (this.cache.size >= this.maxSize) {
      const firstKey = this.cache.keys().next().value;
      this.cache.delete(firstKey);
    }
    
    this.cache.set(key, analysis);
  }

  clear(): void {
    this.cache.clear();
  }
}
```

**Por qu√©:**
- Reduce costos de API (no re-analizar archivos sin cambios)
- Mejora performance en CI/CD

**Uso:**
```typescript
// En AIService
private cache = new AICache();

async analyzeFile(context: AnalysisContext): Promise<AIAnalysis> {
  const cached = this.cache.get(context.fileContent);
  if (cached) {
    return cached;
  }
  
  const result = await this.provider.analyze(context.fileContent, context);
  this.cache.set(context.fileContent, result);
  
  return result;
}
```

---

#### Feature 3.2: Auto-fix con AI
**Crear:** `apps/cli/src/commands/fix.ts`

```typescript
import { AIService } from "../ai/service.js";
import { globFiles } from "../glob.js";
import pc from "picocolors";

interface FixOptions {
  aiProvider: "openai" | "anthropic";
  dryRun: boolean;
}

export async function fixCommand(path: string, options: FixOptions) {
  const apiKey = getAPIKey(options.aiProvider);
  
  if (!apiKey) {
    console.error(pc.red("‚ùå API key requerida para auto-fix"));
    process.exit(1);
  }

  const aiService = new AIService(apiKey, options.aiProvider);
  const files = await globFiles(path, []);

  console.log(pc.green(`üîß Auto-fixing ${files.length} archivos...\n`));

  for (const file of files) {
    const content = await Bun.file(file).text();
    
    const analysis = await aiService.analyzeFile({
      filePath: file,
      fileContent: content,
      existingDiagnostics: []
    });

    const fixes = analysis.issues
      .filter(issue => issue.suggestedFix)
      .sort((a, b) => b.line - a.line); // Aplicar de abajo hacia arriba

    if (fixes.length === 0) {
      console.log(pc.dim(`  ${file} - No fixes needed`));
      continue;
    }

    let fixedContent = content;
    const lines = content.split('\n');

    for (const fix of fixes) {
      // Aplicar el fix (simplificado, necesita l√≥gica m√°s robusta)
      lines[fix.line - 1] = fix.suggestedFix!;
    }

    fixedContent = lines.join('\n');

    if (options.dryRun) {
      console.log(pc.yellow(`  ${file} - Would apply ${fixes.length} fixes`));
    } else {
      await Bun.write(file, fixedContent);
      console.log(pc.green(`  ${file} - Applied ${fixes.length} fixes`));
    }
  }
}
```

**Agregar a CLI:**
```typescript
program
  .command("fix")
  .description("üîß Auto-fix issues usando IA")
  .argument("[path]", "Ruta a analizar", ".")
  .option("--ai-provider <provider>", "Provider: openai, anthropic", "openai")
  .option("--dry-run", "Mostrar cambios sin aplicarlos", false)
  .action(fixCommand);
```

---

#### Feature 3.3: An√°lisis Incremental
**Crear:** `apps/cli/src/utils/git-diff.ts`

```typescript
import { $ } from "bun";

export async function getChangedFiles(): Promise<string[]> {
  try {
    // Archivos cambiados respecto a HEAD
    const result = await $`git diff --name-only HEAD`.text();
    
    // Archivos staged
    const staged = await $`git diff --cached --name-only`.text();
    
    const files = [...result.split('\n'), ...staged.split('\n')]
      .filter(f => f && (f.endsWith('.ts') || f.endsWith('.js')))
      .filter((f, i, arr) => arr.indexOf(f) === i); // √önicos
    
    return files;
  } catch {
    return [];
  }
}
```

**Agregar opci√≥n al CLI:**
```typescript
program
  .command("lint")
  // ... opciones existentes
  .option("--changed-only", "Analizar solo archivos modificados (Git)", false)
  .action(lintCommand);
```

**En el comando:**
```typescript
export async function lintCommand(path: string, options: LintOptions) {
  let files;
  
  if (options.changedOnly) {
    files = await getChangedFiles();
    if (files.length === 0) {
      console.log(pc.green("‚úÖ No hay archivos modificados"));
      return;
    }
  } else {
    files = await globFiles(path, options.ignore);
  }
  
  // ... resto del c√≥digo
}
```

**Por qu√©:**
- En repos grandes, analizar todo con AI es costoso
- `--changed-only` solo analiza lo modificado
- Perfecto para pre-commit hooks

---

### Fase 4: Monetizaci√≥n (1-2 semanas)

#### Feature 4.1: Sistema de Cr√©ditos Propio (Opcional)
**Crear:** Backend con servicio proxy

```typescript
// Backend: apps/api/src/proxy.ts
import express from "express";
import OpenAI from "openai";
import { verifyToken } from "./auth.js";
import { deductCredits } from "./billing.js";

const app = express();

app.post("/api/analyze", async (req, res) => {
  const token = req.headers.authorization?.replace("Bearer ", "");
  
  if (!token) {
    return res.status(401).json({ error: "No token" });
  }

  const user = await verifyToken(token);
  
  if (!user) {
    return res.status(401).json({ error: "Invalid token" });
  }

  // Verificar cr√©ditos
  if (user.credits < 1) {
    return res.status(402).json({ error: "Insufficient credits" });
  }

  // Hacer el request a OpenAI/Claude
  const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  
  const response = await client.chat.completions.create({
    model: "gpt-4-turbo-preview",
    messages: req.body.messages,
    response_format: { type: "json_object" }
  });

  // Deducir cr√©ditos
  await deductCredits(user.id, 1);

  res.json(response);
});
```

**CLI actualizado:**
```typescript
// Si usa tu servicio
if (process.env.VIBRANT_TOKEN) {
  const response = await fetch("https://api.vibrant.dev/analyze", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${process.env.VIBRANT_TOKEN}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({ messages: [...] })
  });
  
  const result = await response.json();
}
```

---

## üéì Gu√≠a para Junior Devs: C√≥mo Implementar Esto

### Paso a Paso para Empezar

#### 1. Setup del Proyecto
```bash
cd C:\Users\FrancoGalfre\Desktop\vibrant

# Instalar dependencias AI
cd apps/cli
bun add openai @anthropic-ai/sdk

# Instalar tipos
bun add -d @types/node
```

#### 2. Crear Estructura de Carpetas
```bash
cd apps/cli/src
mkdir -p ai/providers
mkdir -p ai/__tests__
mkdir -p commands
```

#### 3. Implementar Providers (Uno por Uno)

**Empieza con OpenAI (m√°s simple):**
1. Crea `ai/service.ts` con las interfaces
2. Crea `ai/providers/openai.ts`
3. Testea manualmente con un script:

```typescript
// test-ai.ts
import { OpenAIProvider } from "./ai/providers/openai.js";

const provider = new OpenAIProvider(process.env.OPENAI_API_KEY!);

const result = await provider.analyze(`
const data = fetchUser();
// TODO: implement this
function process(x: any) {
  return x;
}
`, {
  filePath: "test.ts",
  fileContent: "...",
  existingDiagnostics: []
});

console.log(JSON.stringify(result, null, 2));
```

Ejecuta:
```bash
export OPENAI_API_KEY=sk-...
bun run test-ai.ts
```

**Verifica que:**
- El response sea JSON v√°lido
- `confidence` est√© entre 0 y 1
- `issues` sea un array
- Cada issue tenga `line`, `column`, `message`

#### 4. Integrar en CLI (Incremental)

**4.1: Primero solo detectar la flag:**
```typescript
// En cli.ts
.option("--ai", "Enable AI analysis")
.action(async (path, options) => {
  if (options.ai) {
    console.log("AI mode enabled!");
  }
  // ... resto
});
```

Testea:
```bash
bun run cli . --ai
# Deber√≠a imprimir "AI mode enabled!"
```

**4.2: Agregar validaci√≥n de API key:**
```typescript
if (options.ai) {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    console.error("Missing OPENAI_API_KEY");
    process.exit(1);
  }
  console.log("AI mode enabled with key:", apiKey.slice(0, 10) + "...");
}
```

**4.3: Crear instancia de AIService:**
```typescript
let aiService;
if (options.ai) {
  const apiKey = process.env.OPENAI_API_KEY!;
  aiService = new AIService(apiKey, "openai");
  console.log("AI service initialized");
}
```

**4.4: Pasar al runner:**
```typescript
const result = await lint(path, {
  format: options.format,
  ignore: options.ignore.split(","),
  aiService // Pasar aqu√≠
});
```

**4.5: En el runner, analizar un archivo:**
```typescript
// En runner.ts
if (options.aiService) {
  console.log(`Analyzing ${file} with AI...`);
  
  const content = await Bun.file(file).text();
  const analysis = await options.aiService.analyzeFile({
    filePath: file,
    fileContent: content,
    existingDiagnostics: []
  });
  
  console.log("AI found:", analysis.issues.length, "issues");
}
```

#### 5. Testing Progresivo

**Test 1: Archivo simple**
```bash
# Crea un archivo de prueba
echo 'const data = 123; // TODO: implement' > test-ai.ts

# Analiza con AI
bun run cli test-ai.ts --ai --format pretty
```

**Deber√≠a mostrar:**
- Issues de reglas est√°ticas (generic-variable-name, generic-comment)
- Issues de AI (semantic issues)
- Confidence score

**Test 2: Proyecto real**
```bash
bun run cli apps/cli/src --ai
```

**Test 3: Performance**
```bash
time bun run cli . --ai
# Mide cu√°nto tarda
```

#### 6. Debugging Tips

**Si el AI no responde:**
1. Verifica la API key: `echo $OPENAI_API_KEY`
2. Prueba la key directamente:
```typescript
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const test = await openai.chat.completions.create({
  model: "gpt-4-turbo-preview",
  messages: [{ role: "user", content: "Test" }]
});
console.log(test.choices[0].message.content);
```

**Si el parsing falla:**
1. Imprime el response crudo:
```typescript
console.log("Raw response:", response.choices[0].message.content);
```
2. Verifica que sea JSON v√°lido
3. Ajusta el prompt para pedir JSON m√°s expl√≠citamente

**Si es muy lento:**
1. Usa cach√© (ver Feature 3.1)
2. Reduce el tama√±o del prompt
3. Usa modelos m√°s r√°pidos (gpt-3.5-turbo)

---

## üí∞ Estrategia de Monetizaci√≥n Recomendada

### Fase 1: BYOK (Bring Your Own Key) - Lanzamiento
```
Usuarios traen su propia API key de OpenAI/Claude
```

**Ventajas:**
- Zero overhead de billing
- Zero costos de infraestructura
- Focus en producto
- Valida la demanda

**Precio:** GRATIS (open source con flag --ai)

**Objetivo:** Conseguir primeros 100-1000 usuarios

---

### Fase 2: Freemium con Cr√©ditos - Crecimiento
```
- Free: 10 an√°lisis AI/mes
- Pro: $9/mes - 500 an√°lisis
- Team: $49/mes - 5000 an√°lisis
```

**Ventajas:**
- Predictibilidad de ingresos
- Mejor UX (no necesitan API keys)
- Puedes agregar markup a los costos de API

**Desventajas:**
- Necesitas backend
- Necesitas billing (Stripe)
- Necesitas gestionar keys de API

**Objetivo:** $10k MRR (Monthly Recurring Revenue)

---

### Fase 3: Enterprise - Escala
```
- Self-hosted con licencia
- Soporte dedicado
- Custom rules con AI
- SLA garantizado
```

**Precio:** $500-5000/mes seg√∫n tama√±o

**Objetivo:** Grandes empresas

---

## üöÄ Roadmap Sugerido

### Q1 2026 (Ahora - Marzo)
- ‚úÖ [DONE] Architecture AI base
- [ ] Implementar OpenAI provider
- [ ] Testing b√°sico
- [ ] Lanzar en Product Hunt / Reddit
- [ ] Conseguir primeros 100 usuarios

### Q2 2026 (Abril - Junio)
- [ ] Agregar Claude provider
- [ ] Implementar caching
- [ ] Agregar 10 reglas est√°ticas m√°s
- [ ] Auto-fix con AI
- [ ] 1000 usuarios activos

### Q3 2026 (Julio - Septiembre)
- [ ] Backend para cr√©ditos propios
- [ ] Sistema de billing con Stripe
- [ ] Landing page profesional
- [ ] Documentation completa
- [ ] Lanzar plan Pro

### Q4 2026 (Octubre - Diciembre)
- [ ] CI/CD integrations (GitHub Actions, GitLab CI)
- [ ] IDE extensions (VSCode, WebStorm)
- [ ] Team features
- [ ] $10k MRR

---

## üìö Recursos para Aprender

### TypeScript Compiler API
- Docs oficiales: https://github.com/microsoft/TypeScript/wiki/Using-the-Compiler-API
- Tutorial: https://ts-ast-viewer.com (visualiza ASTs)
- Libro: "TypeScript Deep Dive" (gratis)

### AI APIs
- OpenAI Docs: https://platform.openai.com/docs
- Anthropic Docs: https://docs.anthropic.com
- Prompt Engineering Guide: https://www.promptingguide.ai

### CLI Development
- Commander.js: https://github.com/tj/commander.js
- Ink (React for CLIs): https://github.com/vadimdemedes/ink
- Bun Guide: https://bun.sh/guides

### Testing
- Bun Test: https://bun.sh/docs/cli/test
- Vitest (alternativa): https://vitest.dev

---

## ‚ö†Ô∏è Posibles Problemas y Soluciones

### Problema 1: Costos de API se disparan
**S√≠ntomas:** Facturas altas de OpenAI/Claude

**Soluciones:**
1. Implementar rate limiting (m√°ximo N requests por minuto)
2. Cach√© agresivo (ver Feature 3.1)
3. Usar modelos m√°s baratos (gpt-3.5-turbo en lugar de gpt-4)
4. Solo analizar archivos modificados (--changed-only)
5. Limitar tama√±o de archivos (m√°x 500 l√≠neas con AI)

### Problema 2: AI da false positives
**S√≠ntomas:** Reporta c√≥digo bueno como "AI-generated"

**Soluciones:**
1. Ajustar el prompt para ser m√°s conservador
2. Subir el threshold de confidence (solo reportar si > 0.8)
3. Permitir que usuarios den feedback (üëçüëé)
4. Fine-tune del modelo con ejemplos

### Problema 3: Muy lento
**S√≠ntomas:** Tarda minutos en analizar un proyecto

**Soluciones:**
1. An√°lisis paralelo (Promise.all en lugar de bucle secuencial)
2. Streaming de responses (OpenAI/Claude soportan streaming)
3. Cach√©
4. Batch API (analizar m√∫ltiples archivos en un solo request)

### Problema 4: Users no ponen la API key correctamente
**S√≠ntomas:** Errores de autenticaci√≥n

**Soluciones:**
1. Comando para validar key: `vibrant test-ai`
2. Mensajes de error claros y accionables
3. Link a tutorial de c√≥mo conseguir key
4. .env template con ejemplo

---

## üéØ Next Steps (Por Orden de Prioridad)

### 1. Implementar Provider OpenAI (1-2 d√≠as)
- Crear `ai/service.ts` con interfaces
- Implementar `ai/providers/openai.ts`
- Test manual con script

### 2. Integrar en CLI (1 d√≠a)
- Agregar flag `--ai`
- Validar API key
- Pasar AIService al runner

### 3. Modificar Runner (1 d√≠a)
- Llamar a AI para archivos
- Combinar diagn√≥sticos est√°ticos + AI
- Formatear output

### 4. Testing B√°sico (1 d√≠a)
- Crear casos de test
- Validar que funciona end-to-end
- Fix bugs

### 5. Documentation (1 d√≠a)
- Actualizar README con --ai flag
- Tutorial de c√≥mo conseguir API key
- Ejemplos de uso

### 6. Launch (1 d√≠a)
- Tweet sobre el lanzamiento
- Post en Reddit /r/programming, /r/typescript
- Post en Hacker News
- Product Hunt

---

## üìù Checklist de Implementaci√≥n

```markdown
## Fase 1: AI Core
- [ ] Instalar dependencias (openai, @anthropic-ai/sdk)
- [ ] Crear estructura de carpetas (ai/, ai/providers/)
- [ ] Implementar interfaces en ai/service.ts
- [ ] Implementar OpenAIProvider
- [ ] Test manual del provider
- [ ] Implementar AnthropicProvider
- [ ] Test manual del provider

## Fase 2: CLI Integration
- [ ] Agregar flag --ai al comando lint
- [ ] Agregar opci√≥n --ai-provider
- [ ] Implementar validaci√≥n de API key
- [ ] Crear AIService instance en CLI
- [ ] Pasar AIService al runner
- [ ] Modificar runner para usar AI
- [ ] Actualizar formatters para mostrar AI issues

## Fase 3: Testing
- [ ] Unit tests para AIService
- [ ] Integration tests para CLI
- [ ] Test con archivo simple
- [ ] Test con proyecto real
- [ ] Performance testing
- [ ] Fix bugs encontrados

## Fase 4: Documentation
- [ ] Actualizar README.md
- [ ] Crear CONTRIBUTING.md
- [ ] Tutorial: Getting Started with --ai
- [ ] Tutorial: Getting API Keys
- [ ] Ejemplos de uso
- [ ] FAQ

## Fase 5: Launch
- [ ] Build final
- [ ] Publish a npm
- [ ] Crear landing page
- [ ] Post en Twitter
- [ ] Post en Reddit
- [ ] Post en Hacker News
- [ ] Submit a Product Hunt
```

---

## üß† Conclusi√≥n

Tu idea de Vibrant con `--ai` flag es **s√≥lida y comercialmente viable**. Tienes:

1. ‚úÖ **Problema real:** Detectar c√≥digo AI-generated es cada vez m√°s importante
2. ‚úÖ **Arquitectura s√≥lida:** Tu c√≥digo est√° bien estructurado y es extensible
3. ‚úÖ **Modelo de negocio claro:** Freemium -> Pro -> Enterprise
4. ‚úÖ **Tecnolog√≠a moderna:** Bun + TypeScript + AI APIs
5. ‚úÖ **Timing perfecto:** El uso de AI para c√≥digo est√° explotando

**Mi recomendaci√≥n:**

1. Implementa la versi√≥n BYOK (Bring Your Own Key) AHORA
2. L√°nzala en 1-2 semanas
3. Consigue feedback de usuarios reales
4. Itera basado en feedback
5. Una vez que tengas tracci√≥n (100-1000 usuarios), construye el backend para cr√©ditos propios

**No intentes hacer todo perfecto desde el inicio.** Lanza r√°pido, aprende r√°pido, itera r√°pido.

---

## üìû Siguientes Pasos

¬øQuieres que te ayude a:

1. **Implementar el c√≥digo paso a paso?** Puedo escribir cada archivo contigo
2. **Revisar tu c√≥digo actual?** Puedo hacer un code review detallado
3. **Dise√±ar la arquitectura del backend?** Para cuando quieras agregar cr√©ditos propios
4. **Escribir los tests?** Puedo ayudarte con testing
5. **Crear la landing page?** Puedo dise√±ar y desarrollar el sitio web

**Solo dime qu√© parte quieres tacklear primero y arrancamos. üöÄ**

---

*Documento generado: 6 de Febrero, 2026*  
*Pr√≥xima revisi√≥n: Despu√©s de implementar Fase 1*
